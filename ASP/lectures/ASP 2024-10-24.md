# Advanced Statistical Physics: Lecture 6
# $I$ Microscopic and Macroscopic Degrees of Freedom
## $2^\circ$ [[20250219162904|Diffusion]]
## 2.4 [[20250220114905|driven diffusion]]
*[[ASP 2024-10-23|continued]]*
### 2.4.2 [[20250220135508|non-equilibrium particles on a ring]]
Assume a ring with $L$ sites and a [[20250219164452|lattice spacing]] $a$. Particles can jump clockwise with a [[20221021130053|probability]] $p\Gamma$ and anti-clockwise with a probability $(1-p)\Gamma$, where $\Gamma$ denotes the jump rate. A small force $F$ exists, causing jumps in one direction to be preferred.

Even with a [[20250220145117|single particle on a ring]], the [[20250220145242|Einstein relation]] for the [[20250220135154|mobility]] and [[20250220145320|Stokes friction]] can be derived.

#### [[20250220145242|Einstein relation]] & [[20250220145320|Stokes friction]]
The Einstein relation describes the [[20250218123558|diffusion coefficient]] $D$ as dependent on the [[20250220135154|mobility]] $\sigma$, the [[20221020211421|Boltzmann constant]] $k_B$ and the [[20230403104255|temperature]] $T.

$$
\begin{eqnarray}
    D &=& \sigma k_BT
\end{eqnarray}
$$

Instead of the mobility $\sigma$, the [[20250220145320|Stokes friction]] $\gamma=\sigma^{-1}$ can be used.

Stokes friction is macroscopic friction, caused by microscopic fluctuations. These fluctuations can be described with the [[20250218123558|diffusion constant]] $D$.

This is similar to Newton's law with friction. In the overdamped case ($m\rightarrow0$), $v$ is inverse proportional to the friction $\gamma$.

$$
\begin{eqnarray}
    m\dot v &=& F - \gamma v\\
    m\rightarrow0 \Rightarrow v &=& \frac{1}{\gamma} F
\end{eqnarray}
$$

##### [[20250220145117|Proof: ring with single particle]]
The [[20250220145242|Einstein relation]] and [[20250220145320|Stokes friction]] can be derived from the [[20250220135508|driven diffusion on a ring]] with a single particle.

The [[20221021130053|probability]] $p_i$ to find it on a certain position is uniform, due to [[20241010094135|translational invariance]]. Thus, $p_i=L^{-1}$ is constant, while the [[20250220142853|net probability current]] $J$ is non-zero.

$$
\begin{eqnarray}
    J_{i, i+1} &=& P_i\Gamma_{i,i+1} - P_{i+1}\Gamma_{i+1,i} \\
        &=& \frac{1}{L} (2p-1)\Gamma
\end{eqnarray}
$$

Further, the average speed $\braket{v}$ of the particle can be computed from the [[20250219164452|lattice spacing]] $a$. For small forces $F$, this can be described by the [[20250220135154|mobility]] $\sigma$.

$$
\begin{eqnarray}
    \braket{v} &=& (\Gamma_{i,i+1} - \Gamma_{i+1,i})a \\
        &\approx& \frac{1}{2} \Gamma a^2\beta F \\
        &\equiv& \sigma F
\end{eqnarray}
$$

The [[20250218123558|diffusion constant]] $D$ can be derived as follows. This leads to the [[20250220145242|Einstein relation]] for $\sigma$. The microscopic fluctuation (described by $D$) leads to macroscopic [[20250220145320|Stokes friction]] $\gamma^{-1}$.

$$
\begin{eqnarray}
    D &=& \frac{1}{2} \Gamma a^2 \\
    \sigma &=& \frac{1}{2} \Gamma a^2 \\
        &=& \frac{D}{k_BT} \\
        &=& \frac{1}{\gamma} \\
    \Rightarrow D &=& \frac{k_BT}{\gamma}
\end{eqnarray}
$$

##### Example of a nonequilibrium stationary state: Energy production
Let a nonequilibrium stationary state be characterised by a positive entropy production.

If the particle jumps to the right, work $\Delta W=Fa$ is applied, or $\Delta W=-Fa$ if it jumps left. Because the particle prefers jumping to the right, energy is dissipated to the heat bath. This produces entropy $S$.

$$
\begin{eqnarray}
    \dv{S}{t} &\approx& \frac{1}{2}k_B\Gamma
        \left(\frac{Fa}{k_BT}\right)
\end{eqnarray}
$$

#### many particles on the ring
Now, $N$ particles will be on the ring with $L$ sites. The time will be counted in units of $\Gamma\overset{!}{=}1$ and the distance in units of $a\overset{!}{=}1$. An *exclusion interaction* enforces a maximum of a single particle per site. The density is $\rho=\frac{N}{L}$.

This is called [[20231012095625|ASEP]], where *simple* refers to a jump range of $1$.[^2] This was first applied in Biophysics of mRNA translation[^3] in the form of [[20231012095456|TASEP]].

[^2]: Spitzer F. (1970)
[^3]: MacDonald et al. (1968)

#### continuum limit
With $p=0.5$, the system is a *SSEP* (symmetric simple exclusion process).

Consider the average occupation variables $\eta_i$, describing the density $\rho_i$ at position $i$.

$$
\begin{eqnarray}
    \eta_i &=&
        \begin{cases}
            0 & i\text{ vacant} \\
            1 & i\text{ occupied}
        \end{cases} \\
    \rho_i &=& \braket{\eta_i} \\
    \dv{}{t}\braket{\eta_i}
        &=&
            p\braket{\eta_{i-1}(1-\eta_{i})}
            +(1-p)\braket{\eta_{i+1}(1-\eta_{i})} \\
        &&  -(1-p)\braket{\eta_{i}(1-\eta_{i-1})}
            -p\braket{\eta_{i}(1-\eta_{i+1})} \\
    \braket{\eta_{i}(1-\eta_{i+1})} &=& \braket{\eta_i} - \braket{\eta_i\eta_{i+1}}
\end{eqnarray}
$$

For $p\neq0.5$, the quadratic terms do not cancel out. Thus, equations for $\braket{\eta_i\eta_{i\pm1}}$  depend on terms of at least 3rd order. This infinite hierarchy of equation cannot be solved in general.

One possible approach is the so-called *mean field approximation*. Instead, the *master equation* is used. The number of configurations is described by the [[20240521172857|binomial coefficient]] ${L \choose N}$.

An educated guess assumes that the stationary distribution $P^*$ is uniform, thus $P^*={L \choose N}^{-1}$.

##### proof
The guess can be proven by proving the following equality.

$$
\begin{eqnarray}
    \forall \mathcal C:\qquad
    \underbrace{
    \sum_{\mathcal C^\prime}
        \Gamma(\mathcal C^\prime\rightarrow\mathcal C)
        }_\text{total influx}
        &=&
        \underbrace{
            \sum_{\mathcal C^\prime}
            \Gamma(\mathcal C\rightarrow\mathcal C^\prime)
        }_\text{total outflux}
\end{eqnarray}
$$

The flux can be described by the number of states with exactly $1$ particle moving in or out of $\mathcal C$. This depends on the probability $p$ (or $1-p$ for jumps back) and the number of $01$ pairs (or the number of $10$ pairs).

To prove this, the number of $01$ pairs must be equal to the number of the $10$ pairs. Considering *clusters* of at least one particle, each cluster has exactly one vacant space before and after it. Therefore, the ring geometry enforces the equality.

For large systems with $L,N\rightarrow\infty$ with $\rho=\frac{N}{L}$, the states $\braket{\eta_i},\braket{\eta_{i+1}}$ become independent. This is the [[20241030083454|Bernoulli measure]].

Conversely, the stationary state of an open [[20231012095625|ASEP]] is rather complex.

#### mean field approximation
One possible approach is the so-called *mean field approximation* (MFA), i.e. assume that averages factorize. In other words, the variables are assumed to be independent. With this approach, a nonlinear, closed set of equations for $\braket{\eta_i}$ emerge.

$$
\begin{eqnarray}
    \braket{\eta_i\eta_{i+1}} &\approx& \braket{\eta_i}\braket{\eta_{i+1}}
\end{eqnarray}
$$

This is not correct in the general case, because it neglects fluctuations or correlations, described by the [[20221028194035|variance]] $\mathrm{Var}(x)\overset{!}{=}0$.

$$
\begin{eqnarray}
    \forall i\neq j:\braket{x_ix_j} &=& \braket{x_i}\braket{x_j} \\
    \braket{x_i^2} &=& \braket{x_i}^2 \\
    \Rightarrow \mathrm{Var}(x_i) &=& 0
\end{eqnarray}
$$

For example, in the [[20231012095625|ASEP]] the occupation numbers are given as $\eta_i\in\{0,1\}$, the square matches the value itself: $\eta_i^2=\eta_i$. In this case, the MFA does not make sense.

#### Master Equation
The master equation is the general description of a continuous time Markov process. It is the balance equation for the probability $P_t(\mathcal C)$ to find a system in configuration $\mathcal C$ at time $t$.

With this, the full probability distribution of configurations $\mathcal C$  is considered. It is the difference between the *gain term*, where states change to $\mathcal C$, and a *loss term*, where the state moves away from $\mathcal C$. $\Gamma(\mathcal C^\prime\rightarrow\mathcal C)$ is the transition rate from state $\mathcal C^\prime$ to state $\mathcal C$.

$$
\begin{eqnarray}
    \dv{P_t(\mathcal C)}{t}
        &=&
            \underbrace{
                \sum_{\mathcal C^\prime}
                \Gamma(\mathcal C^\prime\rightarrow\mathcal C)
                P_t(\mathcal C^\prime)
            }_\text{gain term}
            -
            \underbrace{
                \sum_{\mathcal C^\prime}
                \Gamma(\mathcal C\rightarrow\mathcal C^\prime)
                P_t(\mathcal C^\prime)
            }_\text{loss term} \\
        &=& \sum_{\mathcal C^\prime} A_{\mathcal C\mathcal C^\prime} P_t(\mathcal C^\prime)
\end{eqnarray}
$$

This can be described as a matrix $A=(A_{\mathcal C\mathcal C^\prime})$. To solve the problem, $A$ needs to be diagonalized.

With long times $t\rightarrow\infty$, the system approaches a *stationary distribution* $P^*(\mathcal C)$ which satisfies following equation. Thus, $P^*$ is an eigenvector with eigenvalue $0$. All other eigenvalues are negative.

$$
\begin{eqnarray}
    \sum_{\mathcal C^\prime} A_{\mathcal C\mathcal C^\prime} P_t(\mathcal C^\prime) &=& 0 \\
    \sum_{\mathcal C^\prime}
        \Gamma(\mathcal C^\prime\rightarrow\mathcal C)
        &=&
            \sum_{\mathcal C^\prime}
            \Gamma(\mathcal C\rightarrow\mathcal C^\prime)
\end{eqnarray}
$$

*[[ASP 2024-10-30|to be continued ...]]*