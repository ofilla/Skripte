# Inference & Machine Learning: Adv. Seminar 9
# SHAP / Shap Values
Mit SHAP values kann man einzelne Outputs eines ML Modells erklären. Dies stärkt das Vertrauen in das Modell, ist aber auch für Debugging oder Verständnis sinnvoll.

Für z.B. [[20230901151622|lineare Regression]] ist dies einfach, für komplexere Modelle wie zufällige Wälder (*random forest*) oder *neurale Netzwerke* jedoch sehr schwierig.

## Shapley values in Game Theory
In cooperative game theory a number of players $p_i$ work together to archive a game value $v$. Shapley values are a way of fairly dividing the games value among the players.

Axioms:
* Efficiency: $v=\sum_i \varphi_i$
* Null Player: A player who does not contribute does get a Shapley value of $\varphi_0=0$
* Additivity: The Shapley values for different games add up $\varphi(A) + \varphi(B) = \varphi(A+B)$
* Symmetry: Two players who contribute the same get the same Shapley value

The Shapley value is the average amount of game value, that the team generates if the player enters the group. In this case, all possible orders of entering a team need to be taken into account.

Weiterhin können die Interaktionen $\varphi_{ij}$ zwischen den Spielern $i$ und $j$ ermittelt werden. Dies sind Korrekturterme zu dem individuellen Beitrag $\varphi_{ii}$ zum Gesamtbeitrag $\varphi_i$.

$$
\begin{eqnarray}
    \phi_i &=& \phi_{ii} + \sum_{i\neq j} \phi_{ij}
\end{eqnarray}
$$

## SHAP for XAI (explainable AI)
Zum Bewerten eines statistischen Modells werden die [[20241106150836|Features]] als Spieler und die [[20241111144345|Vorhersage]] als Spielwert betrachtet.

Im Allgemeinen wächst die Anzahl der Terme exponenziell in der Anzahl der Features. Für Baum-Modelle wie GBT oder Random Forests kann TreeSHAP verwendet werden, um SHAP values in nicht-exponentieller Zeit zu berechnen.