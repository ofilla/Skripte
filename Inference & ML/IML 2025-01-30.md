# Inference & Machine Learning: Adv. Seminar 11
# Kausale Inferenz
by Prof. Dirk Witthaut

### Lord's Paradox
The Lord's Paradox is an example for the application of *causal graphs*, comparable to *Simpson's paradox* in a continuous case.

We assume a boarding school offering two meal plans $A$ and $B$ for one year, called diet $D$. Pupil's weights at the beginning $W_i$ and at the end $W_f$ of the year are measured. Does the choice of a meal plan effect the weight gain?

Assume the results $W_f(W_i)$ follow a [[20230223132329|Gaussian distribution]] around the graph $W_f=W_i$, depicted in following plot.

![Lords Paradox](https://upload.wikimedia.org/wikipedia/commons/c/cc/ParadoxSketch.jpg)

Statistician $1$ computes the gain $G=W_f-W_i$ computes the [[20221028194709|expected values]] $E$ for both plans. Because both $E_A(G)=E_B(G)=0$ he concludes, that the meal plan does not effect the weight.

Statistician $2$ has problems with this. The preferences of the pupils can causally effect both the choice of the meal plan $A/B$ and the initial weight $W_i$, there is a *confounding*, depicted in the following [[20230405205149|graph]].

```dita
         +----> meal plan
         |
preferences
         |
         +----> W_i
```

Dividing the pupils in sub-populations according to $W_i$ breaks the *spurious non-causal dependencies* due to confounding.

For a certain sub-population with $W_i=W_0$, differences emerge.

$$
\begin{eqnarray}
    E(W_f|B) &>& E(W_f|A)
\end{eqnarray}
$$

Both reasonings appear fine. The question which one is correct cannot be answered by the data alone, casual reasoning is required.

#### Pearl's reasoning
Pearl's reasoning uses the causal graph depicted below. The structure coefficients $\pm 1$ (Strukturkoeffizienten) describe the factors in the equation $G=W_f-W_i$.

![Causal Graph by Pearl (2016)](https://upload.wikimedia.org/wikipedia/commons/9/9c/Paradoxcausaldiagram2.png)

Applying the *adjustment formula* proves that statistician $2$ is correct, if confounding exists.

$$
\begin{eqnarray}
    E(W_f|\mathrm{do}(D=A))
        &=& \sum_{w_i} E(W_F|D=A, W_i=w_i)\cdot P(W_i=w_i)
\end{eqnarray}
$$

If a common confounder, e.g. preferences of pupils, effects both initial weight $W_i$ and choice of diet $D$. The non-causal path from $D$ to $W_f$ needs to be eliminated. Since the preferences are unknown, this can only happen dividing $W_i$ into sub-populations.

$$
\begin{eqnarray}
    E(G|\mathrm{do}(D=A))
        &=& \sum_{w_i} E(W_F|D=A, W_i=w_i)\cdot P(W_i=w_i)
\end{eqnarray}
$$

## Structured Causal Models (SMCs)
Structured Causal Models use *causal graphs*. Unobserved effects $U$ are treated as [[20221028195435|random variables]].

For a qualitative model, only parent nodes $PA_i$ and the unobserved effects $U_i$ influence the value of node $X_i$. The other variables do not enter the model directly.

$$
\begin{eqnarray}
    X_i &=& f(PA_i, U_i)
\end{eqnarray}
$$

The following *causal graph* depicts dependencies, but does not show the unmeasured $U_i$.

```ditaa
X -----> Z
| +-<--/ |
| |      |
v /      v
W -----> Y

```

$$
\begin{eqnarray}
    Y &=& f_y(W,Z,U_yu) \\
    Z &=& f_z(X, U_z) \\
    W &=& f_w(X, Z, U_w) \\
    X &=& f_x(U_x)
\end{eqnarray}
$$

### Causal graph
A causal graph is a *directed acyclic graph (DAG)*, where [[20230804154351|nodes]] are the variables of interest and an [[20230804154444|edge]] $A\rightarrow B$ describes a causal effect of $A$ on $B$.

It needs to be acyclic, because it can influence it's state in the future, but that's a different state.

### Linear SCMs
Linear *Structured Causal Models* have linear functions $f_i$. It can answer some interesting questions easily.

In the following example, the *structure constants* $a,b,c,d,e$ are required.

```ditaa
X -----> Z
| +-<--/ |
| |      |
v /      v
W -----> Y

```

$$
\begin{eqnarray}
    Y &=& eW + dZ + U_y \\
    Z &=& aX + U_z \\
    W &=& bX + cZ + U_w \\
    X &=& U_x
\end{eqnarray}
$$

The direct effect of $Z$ on $Y$ is $d$. The total effect of  on  is $d+ce$. $X$ is independent of $Z$ and $\varepsilon$ is the *noise* or *residual*.

$$
\begin{eqnarray}
    Y &=& eW + dZ + U_y \\
        &=& e(bX + cZ + U_w) + dZ + U_y \\
        &=& (d+ce)Z
            + ebX
            + \underbrace{(eU_w+U_y)}_\varepsilon
\end{eqnarray}
$$

### structure constants
Die die Vorfaktoren in linearen SCMs werden Strukturkonstanten genannt. Sie sind *keine* Regressionskoeffizienten!

Im obigen Beispiel sind die Regressionskoeffizienten $r_x=eb$ und $r_z=d+ce$ einer [[20230901151622|linearen Regression]] $Y=r_xX+r_zZ + \varepsilon$ durch die kausalen Effekte bestimmt, aber sie sind nicht gleich.

# Literature
1. Wikipedia: https://en.wikipedia.org/wiki/Lord's_paradox