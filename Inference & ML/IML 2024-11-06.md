# Inference & Machine Learning: Adv. Seminar 3
# Maximum  Likelihood Principle
## Maximum Likelihood
Das Maximieren der [[20241106132819|Likelihood]] $L(\vec \theta; \vec x)$ wird genutzt, um die besten Parameter $\vec\theta$ zu suchen, die eine gegebene [[20230228180810|Wahrscheinlichkeitsverteilung]] $f(\vec x;\vec\theta)$ unter gegebenen Datenpunkten $\vec x$ möglichst optimal beschreiben.

Dies erfolgt in vier Schritten.

1. Wähle eine Klasse an [[20230228180810|Wahrscheinlichkeitsverteilungen]] $f(\vec x; \vec \theta)$ an.
2. Definiere die Likelihood-Funktion $L(\theta; \vec x)$
3. Ermittle die [[20241106133837|log-Likelihood-Funktion]] $l(\theta; \vec x)=\ln(L(\theta; \vec x))$
4. Maximiere $l$ durch $\nabla l(\theta; \vec x) \overset{!}{=}0$.

Schritt $4$ muss oft numerisch erfolgen, da die Suche nach Nullstellen oft zu komplex ist.

Seien Datenpunkte gegeben, die einer [[20230223132329|Gaußverteilung]] $f(\vec x; \vec \theta)$ folgen, dann sollen die Parameter $\theta_i$ dieser Gaußverteilung ermittelt werden. Dabei werden die Datenpunkte als $x_i$ dargestellt. Daraus folgt die Methode der geringsten Fehlerquadrate.


### Likelihood function
The likelihood function $L$ is the probability for parameters $\theta_i$ of a probability distribution $f(\vec x; \vec\theta)$, where $\vec x$ are fixed data.

It is easier to maximize the logarithm $\ln L$. The [[20241023133144|loss function]] is effectively the negative *log-likelihood* $-l(\vec \theta, \vec x)$.

$$
\begin{eqnarray}
    L(\theta; \vec x) &=& \prod_{i=1}^n f(x_i; \vec\theta) \\
    l(\theta; \vec x) &=& \log L(\theta; \vec x) \\
        &=& \sum_{i=1}^n \log f(\vec x; \vec \theta) \\
    \pdv{\vec\theta} l(\theta; \vec x) &\overset{!}{=}& 0
\end{eqnarray}
$$

### Method of Least Squares
Unter der Annahme, dass Daten [[20230223132329|gaußverteilt]] sind, erhält man die Parameter für die Wahrscheinlichkeitsverteilung $f(\vec x; \mu, \sigma)$, die die wahrscheinlichste Wahrscheinlichkeitsverteilung beschreibt. Dies folgt aus dem *maximum likelihood principle*.

$$
\begin{eqnarray}
    f(\vec x; \mu, \sigma)
        &=& \frac{1}{\sqrt{2\pi\sigma^2}}
            \exp\left[-\frac{(x-\mu)^2}{2\sigma^2}\right] \\
    \Rightarrow L(\mu, \sigma; \vec x)
        &=& \frac{1}{\sqrt{2\pi\sigma^2}}
            \exp\left[-\frac{(x-\mu)^2}{2\sigma^2}\right] \\
    \Rightarrow l(\mu, \sigma; \vec x)
        &=& - n \log \sqrt{2\pi\sigma^2}
            + \sum_{i=1}^n -\frac{(x_i-\mu)^2}{2\sigma^2} \\
    \pdv{\vec\theta} l(\theta; \vec x) &\overset{!}{=}& 0 \\
        \Rightarrow \mu &=& \frac{1}{n} \sum_{i=1}^n x_i \\
        \Rightarrow \sigma &=& \frac{1}{n} \sum_{i=1}^n (x_i-\mu)^2 \\
\end{eqnarray}
$$

### Beispiel: Experiment
Im Folgenden wird der freie Fall als Beispiel zur Anwendung der [[20241106133055|maximalen Likelihood]] gewählt.

Angenommen, es wird ein Experiment zum freien Fall durchgeführt. Dann beschreibt das physikalische Modell $v(t) = g\cdot t$ die Geschwindigkeit, proportional zu einem Parameter $g\in\mathbb R_+$.

Die $i$-te Messung liefert $v_i=g\cdot t_i +\epsilon_i$ ein Ergebnis mit einer Abweichung $\epsilon_i$. Dann folgt die Verteilung $f$. Damit kann der optimale Parameter mit der [[20241106141953|Methode der kleinsten Fehlerquadrate]] (MLQ) ermittelt werden.

$$
\begin{eqnarray}
    f(\{v_i, t_i\}; g, \sigma) &=& \frac{1}{\sqrt{2\pi\sigma^2}} \exp[-\frac{(v_i-gt_i)^2}{2\sigma^2}] \\
    \Rightarrow -l &=& \frac{1}{2\sigma^2}\sum_{i=1}^n (v_i-gt_i)^2 - n\log \frac{1}{\sqrt{2\pi\sigma^2}}
\end{eqnarray}
$$

Als Verallgemeinerung kann $g$ als Funktion $g(t)$ angenommen werden. Auch hier folgt die MLQ.

$$
\begin{eqnarray}
    f(\{v_i, t_i\}; g, \sigma) &=& \frac{1}{\sqrt{2\pi\sigma^2}} \exp[-\frac{(v_i-g(t_i))^2}{2\sigma^2}] \\
    \Rightarrow -l &=& \frac{1}{2\sigma^2}\sum_{i=1}^n (v_i-g(t_i))^2 - n\log \frac{1}{\sqrt{2\pi\sigma^2}}
\end{eqnarray}
$$

Weiterhin kann $\epsilon$ als exponentiell verteilt angenommen werden. Hierbei sei $g$ wiederum konstant. In diesem Fall liefert eine andere Methode als die MLQ die optimale Lösung.

$$
\begin{eqnarray}
    f(\varepsilon_i) &=& \frac{\lambda}{2} \exp[-\lambda |\varepsilon_i|] \\
    \Rightarrow -l &=& \lambda \sum_{i=1}^n |v_i-gt_i| - n\log \frac{\lambda}{2}
\end{eqnarray}
$$

## Probability vs. Likelihood
### Likelihood
Die Likelihood $L(\vec \theta; \vec x)$ beschreibt die Wahrscheinlichkeit, dass die Parameter $\vec \theta$ die gegebene [[20230228180810|Wahrscheinlichkeitsverteilung]] $f(\vec x; \vec \theta)$ mit gegebene Daten $\vec x$ beschreibt.

Hierbei wird eine Wahrscheinlichkeitsverteilung $f$ angenommen, weiterhin sind die Datenpunkte $\vec x$ vorgegeben. Die besten Parameter können durch das [[20241106133055|Prinzip der maximalen Likelihood]] ermittelt werden.

Beispielsweise die Messung von Werten benutzt Likelihood, anstelle von [[20221021130053|Wahrscheinlichkeit]]: Für gegebene Messwerte $\vec x$ müssen die besten (gemessenen) Parameter ermittelt werden.

Für ein gegebenes Set $(\vec x, \vec \theta)$ sind [[20221021130053|Wahrscheinlichkeit]] $P(\vec x;\vec \theta)$ und Likelihood $L(\vec \theta; \vec x)$ identisch.

$$
\begin{eqnarray}
    L(\vec \theta; \vec x) &=& P(\vec x; \vec \theta)
\end{eqnarray}
$$

### [[20221021130053|Wahrscheinlichkeit]]
Unter *probability* versteht man die Suche nach dem wahrscheinlichsten Zustand / den wahrscheinlichsten Daten $\vec x$, die einer Wahrscheinlichkeitsverteilung $f(\vec x, \vec \theta)$ mit parametern $\theta_i$ folgen.

## [[20241106144442|logistische Regression]]
Die logistische Regression ist ein Verfahren der [[20241023132107|classification]].

Dabei wird einem Ereignis ein diskretes Ergebnis $\gamma$, meist $\gamma=0;1$, zugewiesen. In diesem Fall ist [[20230901151622|lineare Regression]] keine Lösung. Stattdessen wird die *logistische Funktion* $f(X; \beta_0, \beta_1)$ verwendet, die einen Wert zwischen $0$ und $1$ zurückgibt. 

$$
\begin{eqnarray}
    P(Y=1) &=& f(X; \beta_0, \beta_1) \\
    P(Y=0) &=& 1 - f(X; \beta_0, \beta_1) \\
    f(X; \beta_0, \beta_1)
        &=& \frac{\exp[\beta_0+\beta_1X]}{1+\exp[\beta_0+\beta_1X]}
\end{eqnarray}
$$

Dies kann aus dem maximum likelihood-Prinzip hergeleitet werden. Die Maximierung der Funktion $l$ erfolgt meist numerisch, da dies analytisch sehr komplex ist.

$$
\begin{eqnarray}
    L(\beta_0, \beta_1; \vec x)
        &=& \prod_{i: Y_i=1}^n f(x_i; \beta_0, \beta_1)
            \cdot \prod_{i: Y_i=0}^n 1 - f(x_i; \beta_0, \beta_1) \\
        &=& \prod_{i=1}^n (f(x_i; \beta_0, \beta_1))^{Y_i}
            \cdot (1-f(x_i; \beta_0, \beta_1))^{1-Y_i} \\
    \Rightarrow l(\beta_0, \beta_1; \vec x)
        &\equiv& \log L(\beta_0, \beta_1; \vec x) \\
        &=& \sum_{i=0}^n y_i(\beta_0+\beta_1 x_i) - \ln(1+\exp[\beta_0+\beta_1x_i])
\end{eqnarray}
$$
