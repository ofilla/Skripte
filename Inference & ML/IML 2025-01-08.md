# Inference & Machine Learning: Adv. Seminar 10
# Causal Inference Introduction
by Bianca Bannenberg
## Correlation vs. Causation

### Causal Inference
Causal [[20241023125232|inference]] wants to learn from data.

[[20230818103221|Korrelation]] does not imply *causation*. For example, the number of skincare specialists in Kentucky can be correlated to the number of Google searches "how to hide a body".

### Simpson's paradox
Additional information lead to paradox in the numbers.

For example, if $50\%$ of $700$ sick patients take drugs. From the people with drugs, 78% recovered, while 83% recovered otherwise. Splitting up into male/female, the drug increases the chance for recovery for both sexes. From this segregated data, the information improves the understanding.

But in general, more information does not lead to better information. In the same example, the drug lowers blood pressure, but has a toxic side effect. Again, 50% of people take the drug. Segregation by people with high vs. low blood pressure *after treatment* reveales that the drug is harmful in both groups. Still, the overall recovery rate is positive (with the same number as in the first case). Here

In the second case, the segregation does not increase understanding, because the segregation by blood pressure is caused by the drug. In the first example, the a patients sex caused the drugs effect.

"Angebot & Nachfrage" == "Law of Supply" / "Law of Demand(?)"

### Graphical models
A graphical model uses [[20230405205149|graphs]]. Two [[20230804154351|nodes]] are be [[20230818103221|correlated]], when when they are connected by an [[20230804154444|edge]].

In the *chain* $X\rightarrow Y \rightarrow Z$, $Y$ is a *mediator*. E.g. it could be the chain $X=\mathrm{Fire}$, $Y=\mathrm{Smoke}$ and $Z=\mathrm{Alarm}$. Here, $X,Y$ and $Y,Z$ are causal.

In a *fork* $X\leftarrow Y \rightarrow Z$, $Y$ is a common *confounder* of X and Z. Thus, X and Z are correlated, but not causal.

Another structure is a *collider* $X\rightarrow Y \leftarrow Z$. In this case, $X$ and $Z$ could act against each other.

### Example: French power price prediction
The price $P$ for electricity in France was analysed.

For example, the date $D$ causally effects both the load $L$ in a power grid and the nuclear capacity $NC$, which describes the available power created by nuclear plants. Both $L$ and $NC$ causally influence the price $P$ by the *law of supply*.

In the following graph, the arrows show the causality. The "dotted" line, however, shows a correlation between $NC$ and $P$, which is due to indirect connections, that are *not* causal. E.g. the nuclear capacity $NC$ does not effect the date $D$, thus the correlation is not causal.

```ditaa
D --------------------> L
|                       |
|   + - - - - - - - +   |
|                       |
|   |               |   |
|                       |
|   |               |   |
|                       |
v /                  \  v
C --------------------> P
```
