# Inference & Machine Learning: Adv. Seminar 11
# Kausale Inferenz

## I. Causality, Confounding, Data
A standard question in medicine asks for the effect of a new drug / treatment / vaccination.

To avoid *confounding*, a randomised control trial is desiderable. However, in many fields it is impossible.

It can be distinguished between *direct effect* (e.g. V influences health status) and *indirect effects*, e.g. knowing about V can influence health, due to the placebo effect.

Let $V=\{0;1\}$ describe if a vaccination against COVID-19 was taken. We want know the causal effect, if the vaccination prevents a "starken Krankheitsverlauf".

### randomized control trial
To avoid *confounding*, $V$ is chosen at random for every participant in the study. Every difference in the effect between both populations (with either $V=1$ or $V=0$) must be due to the drug / treatment / vaccination, because everything else is the same.

### Confounding
Eine Variable beeinflusst sowohl Ursache als auch Effekt.

In graphical models, there must be *no* further variable effecting the random variable $V$. I.e., there may be no arrow pointing towards $V$. A *fork* $X\leftarrow Y \rightarrow Z$ is allowed to determine a causality $Y\rightarrow Z$, but an additional [[20230804154444|edge]] $X\rightarrow Y$ is forbidden.

For example, the success of treatment may be effected by e.g. the age, but the age must not effect if a person is vaccinated.

## II. Conditional Probability
Dependencies are described by [[20241111133325|conditional probabilities]] $P(A=a|B=b$). These dependencies are of *statistical* nature only! Usually, $P(A=a|B=b)$ can be interpreted as filtering data $A$ with condition $B=b$.

This is not suited to say anything about causal effects of $B$ on $A$, because $A$ and $B$ can be influenced by any other variable $C$. We have a spurious, non-causal path  $B\leftarrow C \rightarrow A$. This causes the filter $P(A|B)$ to filter on variable $C$ indirectly, too.

## III. Interventions / interventional probability
Since [[20241111133325|conditional probability]] is not suited to inference causality, since it describes filtering on data points where $B$ occurred naturally.

In contrast, for causality we want to know what happens if $B$ is *set* to $B=b$ from outside. This ignores the dependence on variable $C$ and is called *intervention* $\mathrm{do}$.

$P(A=a|\mathrm{do}(B=b))$ describes the [[20221021130053|probability]] to observe $A=a$ if an intervention on $B$ is taken such that it assumes the value $B=b$.

### case 1: randomised control trial
The treatment is chosen at random, i.e. it is [[20221028193625|independent]] on any other variable.

In this case, the *interventional probability* and the [[20241111133325|conditional probability]] are the same: $P(A=a|\mathrm{do}(B=b))=P(A=a|B=b)$.

### case 2: Rewrite the trial
Generalise case 1 such that both the treatment $T$ and the age $A$ influence the health $H$ of a patient, but there is no interaction between $T$ and $A$. I.e., no other variable may causally influence $T$. The [[20230405205149|graph]] is $T\rightarrow H \leftarrow A$.

As in case 1, both probabilities are the same.

### case 3: confounding variables
Generalise case 2, such that that a variable $C$ influences $T$. For example, the study takes part in a certain country. Assume $C$ does not effect $A$ and $H$ directly, with the graph $C\rightarrow T\rightarrow H \leftarrow A$.

The clinical trial still works, and the *interventional probability* and the [[20241111133325|conditional probability]] are the same.

### general finding
The [[20241111133325|conditional probability]] and the interventional probability are the same, if there is no *backdoor path* from $T$ to $H$.

A backdoor path is a path that goes from a variable to the effect $H$ on at least two ways, one of them influencing $T$. This destroys the independence of $T$.

## IV. The adjustment formula
How can *interventional probabilities* be computed, if interventions are not possible?

The problem is a spurious, non-causal path from $A$ to $R$ in the [[20230405205149|graph]] $A\rightarrow R\leftarrow L$ with the additional [[20230804154444|edge]] $L\rightarrow A$.

```ditaa
+-- L --+
|       |
v       v
A ----> R
```

Assume a modified graph, closing the *backdoor path*.

```ditaa
    L --+
        |
        v
A ----> R
```

The modified probability $P_m(L=\ell)=P(L=\ell)$ is the same, since the energy requirement is the same as before. Also, $P(R=r|A=a,L=\ell)=P_m(R=r|A=a,L=\ell)$, since the electricity market still works the same way. Both cases are independent on the availability $A$.

Now, the *interventional probability* can be computed. Since there is no backdoor path, it is the same as the [[20241111133325|conditional probability]]. Here, the [[20241120131359|law of total probability]] is applied.

$$
\begin{eqnarray}
    P(R=r|\mathrm{do}(A=a))
        &=& P_m(R=r|\mathrm{do}(A=a)) \\
        &=& P_m(R=r|A=a) \\
        &=& \sum_\ell P_m(R=r|A=a,L=\ell)
            \underbrace{P_m(L=\ell|A=a)}_{\text{no link in mod. graph}} \\
        &=& \sum_\ell P_m(R=r|A=a,L=\ell)P_m(L=\ell) \\
        &=& \sum_\ell P(R=r|A=a,L=\ell)P(L=\ell)
\end{eqnarray}
$$

Block the spurious *backdoor path* $A\leftarrow L \rightarrow R$ by fixing $L$. That is dividing the data into chunks with fixed *confounder* $L$. For each chunk, the statistics can be done independently. This result can be combined to get the final interventional probability by taking the [[20230901150515|weighted average]].

### Generalisation
Assume a large *causal graph* to know the causal effect $X\rightarrow Y$.

Pick a set of variables or [[20230804154351|nodes]] $\{Z_1,\dots,Z_n\}$ such that all *backdoor paths* are blocked and that $Z_j$ is no descendant of $X$. The latter is required to exclude problems by *colliders*.

Then, the interventional probability can be calculated by taking the [[20230901150515|weighted average]].

$$
\begin{eqnarray}
    P(Y=y|\mathrm{do}(X=x))
        &=& \sum_{Z_1,\dots,Z_n}
            P(Y|X=x,Z_1=z_1,\dots,Z_n=z_n) \\
        &&
            \qquad\qquad\qquad
            \cdot P(Z_1=z_1,\dots,Z_n=z_n)
\end{eqnarray}
$$
